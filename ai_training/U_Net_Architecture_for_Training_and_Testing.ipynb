{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mounting Drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Training Dataset\n",
    "images = np.load(\"/content/drive/MyDrive/galaxy_galaxy_train_images.npy\")\n",
    "labels = np.load(\"/content/drive/MyDrive/galaxy_galaxy_train_labels.npy\")\n",
    "images = images.reshape((images.shape[0], images.shape[1], images.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Images and Labels for Preprocessing\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], 1))\n",
    "y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], y_val.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train_datagen = ImageDataGenerator(zoom_range=0.5)\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "def dual_image_generator(images, labels, batch_size=32):\n",
    "    image_gen = train_datagen.flow(images, batch_size=batch_size, seed=42)\n",
    "    label_gen = train_datagen.flow(labels, batch_size=batch_size, seed=42)\n",
    "\n",
    "    while True:\n",
    "        img_batch = next(image_gen)\n",
    "        lbl_batch = next(label_gen)\n",
    "        lbl_batch = lbl_batch.squeeze(-1)\n",
    "        lbl_batch = np.round(lbl_batch).astype(int)\n",
    "        lbl_batch = np.clip(\n",
    "            lbl_batch, 0, 3\n",
    "        )  # lbl_batch = np.clip(lbl_batch, 0, 4) for galaxy-quasar lenses\n",
    "        yield img_batch, lbl_batch\n",
    "\n",
    "\n",
    "train_generator = dual_image_generator(X_train, y_train, batch_size=32)\n",
    "val_generator = dual_image_generator(X_val, y_val, batch_size=32)\n",
    "\n",
    "steps_per_epoch = len(X_train) // 32\n",
    "validation_steps = len(X_val) // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Block\n",
    "def attention_block(x, g, inter_channels):\n",
    "    theta_x = layers.Conv2D(inter_channels, (1, 1), padding=\"same\")(x)\n",
    "    phi_g = layers.Conv2D(inter_channels, (1, 1), padding=\"same\")(g)\n",
    "    f = layers.add([theta_x, phi_g])\n",
    "    f = layers.Activation(\"relu\")(f)\n",
    "    psi = layers.Conv2D(1, (1, 1), activation=\"sigmoid\", padding=\"same\")(f)\n",
    "    return layers.multiply([x, psi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice Coefficient and Dice Loss\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[0, 1, 2])\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss\n",
    "def focal_loss(gamma=2.0, alpha=0.25, smooth_eps=1e-6):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, smooth_eps, 1 - smooth_eps)\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        true_class_probs = tf.reduce_sum(\n",
    "            y_pred * tf.one_hot(y_true, depth=tf.shape(y_pred)[-1]), axis=-1\n",
    "        )\n",
    "        ce_loss = -tf.math.log(true_class_probs)\n",
    "        modulating_factor = tf.pow(1 - true_class_probs, gamma)\n",
    "        focal_loss = alpha * modulating_factor * ce_loss\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return dice_loss(y_true, y_pred) + focal_loss()(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "def attention_unet(input_shape):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    c1 = layers.Dropout(0.1)(c1)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(p1)\n",
    "    c2 = layers.Dropout(0.1)(c2)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(p2)\n",
    "    c3 = layers.Dropout(0.2)(c3)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(p3)\n",
    "    c4 = layers.Dropout(0.2)(c4)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c4)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(p4)\n",
    "    c5 = layers.Dropout(0.3)(c5)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(c5)\n",
    "\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n",
    "    attn4 = attention_block(c4, u6, inter_channels=512)\n",
    "    u6 = layers.concatenate([u6, attn4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(u6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n",
    "    attn3 = attention_block(c3, u7, inter_channels=256)\n",
    "    u7 = layers.concatenate([u7, attn3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(u7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n",
    "    attn2 = attention_block(c2, u8, inter_channels=128)\n",
    "    u8 = layers.concatenate([u8, attn2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n",
    "    attn1 = attention_block(c1, u9, inter_channels=64)\n",
    "    u9 = layers.concatenate([u9, attn1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(u9)\n",
    "\n",
    "    outputs = layers.Conv2D(4, (1, 1), activation=\"softmax\")(\n",
    "        c9\n",
    "    )  # outputs = layers.Conv2D(5, (1, 1), activation='softmax')(c9) for Galaxy-Quasar Lenses\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=\"adam\", loss=combined_loss, metrics=[dice_coefficient])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1\n",
    ")\n",
    "lr_schedule = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "input_shape = (128, 128, 1)\n",
    "model = attention_unet(input_shape=input_shape)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stop, lr_schedule],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving The Model\n",
    "model.save(\"/content/drive/MyDrive/lensed_galaxy_segmentation_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing/validation Set\n",
    "X_test = np.load(\"/content/drive/MyDrive/galaxy_galaxy_test_images.npy\")\n",
    "y_test = np.load(\"/content/drive/MyDrive/galaxy_galaxy_test_labels.npy\")\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_true = y_test.flatten()\n",
    "y_pred = np.argmax(predictions, axis=-1).flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "recall = recall_score(y_true, y_pred, average=None)\n",
    "f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU and Dice Score\n",
    "num_classes = 4  # num_classes = 5 for galaxy-quasar lenses\n",
    "\n",
    "\n",
    "def iou_score(y_true, y_pred, num_classes):\n",
    "    \"\"\"\n",
    "    Computes Intersection over Union (IoU) for each class and mean IoU.\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = np.logical_and(y_true == cls, y_pred == cls).sum()\n",
    "        union = np.logical_or(y_true == cls, y_pred == cls).sum()\n",
    "        if union == 0:\n",
    "            ious.append(float(\"nan\"))\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "\n",
    "    return np.nanmean(ious), ious\n",
    "\n",
    "\n",
    "def dice_score(y_true, y_pred, num_classes):\n",
    "    \"\"\"\n",
    "    Computes Dice Coefficient for each class and mean Dice Score.\n",
    "    \"\"\"\n",
    "    dice_scores = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = 2 * np.logical_and(y_true == cls, y_pred == cls).sum()\n",
    "        denominator = (y_true == cls).sum() + (y_pred == cls).sum()\n",
    "        if denominator == 0:\n",
    "            dice_scores.append(float(\"nan\"))\n",
    "        else:\n",
    "            dice_scores.append(intersection / denominator)\n",
    "\n",
    "    return np.nanmean(dice_scores), dice_scores\n",
    "\n",
    "\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes Pixel Accuracy.\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "mean_iou, per_class_iou = iou_score(y_true, y_pred, num_classes)\n",
    "mean_dice, per_class_dice = dice_score(y_true, y_pred, num_classes)\n",
    "pixel_acc = pixel_accuracy(y_true, y_pred)\n",
    "\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "print(f\"Per-Class IoU: {per_class_iou}\")\n",
    "print(f\"Mean Dice Score: {mean_dice:.4f}\")\n",
    "print(f\"Per-Class Dice Score: {per_class_dice}\")\n",
    "print(f\"Pixel Accuracy: {pixel_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
